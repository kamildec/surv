{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SurvSHAP(t): Time-Dependent Explanations Of Machine Learning Survival Models\n",
    "### M. Krzyzi≈Ñski, M. Spytek, H. Baniecki, P. Biecek\n",
    "## Experiment 1: Evaluating explanations on synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data and models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/exp1_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "X = data.iloc[:, :5]\n",
    "y = Surv.from_dataframe(\"event\", \"time\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "cph.fit(X, y)\n",
    "cph.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "rsf = RandomSurvivalForest(random_state=42, n_estimators=100, min_samples_split=8, min_samples_leaf=4, max_features=3, max_samples=0.8)\n",
    "rsf.fit(X, y)\n",
    "rsf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating performance of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import brier_score, integrated_brier_score\n",
    "# mask created to enable for calculating Brier score\n",
    "mask = (y[\"time\"] < y[y[\"event\"]==1][\"time\"].max()) & (y[\"time\"] > y[y[\"event\"]==1][\"time\"].min())\n",
    "times = np.percentile(y[mask][\"time\"], np.linspace(0.1, 99.9, 101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survs_rsf = rsf.predict_survival_function(X[mask])\n",
    "survs_cph = cph.predict_survival_function(X[mask])\n",
    "preds_rsf = [fn(times) for fn in survs_rsf]\n",
    "preds_cph = [fn(times) for fn in survs_cph]\n",
    "brier_rsf = brier_score(y, y[mask], preds_rsf, times)\n",
    "brier_cph = brier_score(y, y[mask], preds_cph, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame({\"time\": times, \"brier_score\":  brier_rsf[1], \"label\": \"RSF\"}),\n",
    "            pd.DataFrame({\"time\": times, \"brier_score\":  brier_cph[1], \"label\": \"CPH\"})]).to_csv(\"results/exp1_model_brier_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_brier_score(y, y[mask], preds_rsf, times), integrated_brier_score(y, y[mask], preds_cph, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survshap import SurvivalModelExplainer, PredictSurvSHAP, ModelSurvSHAP\n",
    "rsf_exp = SurvivalModelExplainer(rsf, X, y)\n",
    "cph_exp = SurvivalModelExplainer(cph, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_survshap_global_rsf = ModelSurvSHAP(random_state=42)\n",
    "exp1_survshap_global_rsf.fit(rsf_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pickles/exp1_survshap_global_rsf\", \"wb\") as file:\n",
    "    pickle.dump(exp1_survshap_global_rsf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_survshap_global_cph = ModelSurvSHAP(random_state=42)\n",
    "exp1_survshap_global_cph.fit(cph_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp1_survshap_global_cph\", \"wb\") as file:\n",
    "    pickle.dump(exp1_survshap_global_cph, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating ground-truth SurvSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "def shap_kernel(\n",
    "    explainer, new_observation, function_type, timestamps, baseline_f, simplified_inputs, kernel_weights, n\n",
    "):\n",
    "    data = generate_data(n)\n",
    "\n",
    "    shap_values, r2 = calculate_shap_values(\n",
    "        explainer.model,\n",
    "        function_type,\n",
    "        baseline_f,\n",
    "        data,\n",
    "        simplified_inputs,\n",
    "        kernel_weights,\n",
    "        new_observation,\n",
    "        timestamps,\n",
    "    )\n",
    "    result_shap = pd.DataFrame(\n",
    "        shap_values, columns=[\" = \".join([\"t\", str(time)]) for time in timestamps]\n",
    "    )\n",
    "\n",
    "    return result_shap, r2\n",
    "\n",
    "\n",
    "def generate_shap_kernel_weights(simplified_inputs, num_variables):\n",
    "    weights = []\n",
    "    for coalition_vector in simplified_inputs:\n",
    "        num_available_variables = np.count_nonzero(coalition_vector)\n",
    "        if num_available_variables == 0 or num_available_variables == num_variables:\n",
    "            weights.append(1e9)\n",
    "        else:\n",
    "            weights.append(\n",
    "                (num_variables - 1)\n",
    "                / (\n",
    "                    math.comb(num_variables, num_available_variables)\n",
    "                    * num_available_variables\n",
    "                    * (num_variables - num_available_variables)\n",
    "                )\n",
    "            )\n",
    "    return weights\n",
    "\n",
    "\n",
    "def make_prediction_for_simplified_input(\n",
    "    model, function_type, data, simplified_inputs, new_observation, timestamps\n",
    "):\n",
    "    preds = np.zeros((len(simplified_inputs), len(timestamps)))\n",
    "    for i, mask in enumerate(simplified_inputs):\n",
    "        X_tmp = pd.DataFrame(\n",
    "            np.where(mask, new_observation, data), columns=data.columns\n",
    "        )\n",
    "        preds[\n",
    "            i,\n",
    "        ] = calculate_mean_function(model, function_type, X_tmp, timestamps)\n",
    "    return preds\n",
    "\n",
    "def calculate_mean_function(model, function_type, data, timestamps):\n",
    "    if function_type == \"sf\":\n",
    "        all_functions = model.predict_survival_function(data)\n",
    "    elif function_type == \"chf\":\n",
    "        all_functions = model.predict_cumulative_hazard_function(data)\n",
    "    all_function_vals = [f(timestamps) for f in all_functions]\n",
    "    return np.mean(all_function_vals, axis=0)\n",
    "\n",
    "\n",
    "def calculate_shap_values(\n",
    "    model,\n",
    "    function_type,\n",
    "    avg_function,\n",
    "    data,\n",
    "    simplified_inputs,\n",
    "    shap_kernel_weights,\n",
    "    new_observation,\n",
    "    timestamps,\n",
    "):\n",
    "    W = np.diag(shap_kernel_weights)\n",
    "    X = np.array(simplified_inputs)\n",
    "    R = np.linalg.inv(X.T @ W @ X) @ (X.T @ W)\n",
    "    y = (\n",
    "        make_prediction_for_simplified_input(\n",
    "            model, function_type, data, simplified_inputs, new_observation, timestamps\n",
    "        )\n",
    "        - avg_function\n",
    "    )\n",
    "    shap_values = R @ y\n",
    "    y_pred = X @ shap_values\n",
    "    r2 = [None] * y.shape[1]\n",
    "    for i in range(y.shape[1]):\n",
    "        r2[i] = r2_score(y[:, i], y_pred[:, i], sample_weight=shap_kernel_weights)\n",
    "    return shap_values, r2\n",
    "\n",
    "def generate_data(n):\n",
    "    x1 = np.random.binomial(1, 0.5, n)\n",
    "    x2 = np.random.binomial(1, 0.5, n)\n",
    "    x3 = np.random.normal(10, 2, n)\n",
    "    x4 = np.random.normal(20, 4, n)\n",
    "    x5 = np.random.normal(0, 1, n)\n",
    "    return  pd.DataFrame({\"x1\": x1, \"x2\": x2, \"x3\": x3, \"x4\": x4, \"x5\": x5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functions_rsf = rsf.predict_survival_function(X)\n",
    "all_functions_vals = [f.y for f in all_functions_rsf]\n",
    "timestamps = all_functions_rsf[0].x\n",
    "baseline_f = np.mean(all_functions_vals, axis=0)\n",
    "simplified_inputs = [list(z) for z in itertools.product(range(2), repeat=5)]\n",
    "kernel_weights = generate_shap_kernel_weights(simplified_inputs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y[\"event\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth = pd.DataFrame()\n",
    "to_calculate = list(X_test.index)\n",
    "for i in tqdm(to_calculate):\n",
    "    shap_gt = shap_kernel(\n",
    "        rsf_exp, X.iloc[[i]], \"sf\", timestamps, baseline_f, simplified_inputs, kernel_weights, 10000\n",
    "    )\n",
    "    shap_gt[0].insert(0, \"index\", i)\n",
    "    shap_groundtruth = pd.concat([shap_groundtruth, shap_gt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth.to_csv(\"results/exp1_shap_groundtruth_rsf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_functions_cph = cph.predict_survival_function(X)\n",
    "all_functions_vals = [f.y for f in all_functions_cph]\n",
    "timestamps = all_functions_cph[0].x\n",
    "baseline_f = np.mean(all_functions_vals, axis=0)\n",
    "simplified_inputs = [list(z) for z in itertools.product(range(2), repeat=5)]\n",
    "kernel_weights = generate_shap_kernel_weights(simplified_inputs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth_cph = pd.DataFrame()\n",
    "to_calculate = list(X_test.index)\n",
    "for i in tqdm(to_calculate):\n",
    "    shap_gt = shap_kernel(\n",
    "        cph_exp, X.iloc[[i]], \"sf\", timestamps, baseline_f, simplified_inputs, kernel_weights, 10000\n",
    "    )\n",
    "    shap_gt[0].insert(0, \"index\", i)\n",
    "    shap_groundtruth_cph = pd.concat([shap_groundtruth_cph, shap_gt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth_cph.to_csv(\"results/exp1_shap_groundtruth_cph.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_grountruth_rsf = pd.read_csv(\"results/exp1_shap_groundtruth_rsf.csv\")\n",
    "shap_grountruth_cph = pd.read_csv(\"results/exp1_shap_groundtruth_cph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp1_survshap_global_rsf\", \"rb\") as file:\n",
    "    exp1_survshap_global_rsf = pickle.load(file)\n",
    "with open(\"pickles/exp1_survshap_global_cph\", \"rb\") as file:\n",
    "    exp1_survshap_global_cph = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SurvSHAP(t) values plot example\n",
    "\n",
    "example_rsf = deepcopy(exp1_survshap_global_rsf.individual_explanations[690])\n",
    "example_cph = deepcopy(exp1_survshap_global_cph.individual_explanations[690])\n",
    "\n",
    "melted_example_rsf = pd.melt(example_rsf.result, id_vars=\"variable_name\", value_vars=example_rsf.result.columns[6:])\n",
    "melted_example_rsf[\"variable\"] = melted_example_rsf[\"variable\"].str[4:].astype(float)\n",
    "melted_example_rsf.to_csv(\"results/exp1_example_rsf.csv\", index=False)\n",
    "melted_example_cph = pd.melt(example_cph.result, id_vars=\"variable_name\", value_vars=example_cph.result.columns[6:])\n",
    "melted_example_cph[\"variable\"] = melted_example_cph[\"variable\"].str[4:].astype(float)\n",
    "melted_example_cph.to_csv(\"results/exp1_example_cph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized SurvSHAP(t) values plot example\n",
    "\n",
    "example_rsf.result.iloc[:, 5:] = np.nan_to_num(\n",
    "            example_rsf.result[example_rsf.result[\"B\"] == 0].iloc[:, 5:]\n",
    "            / example_rsf.result[example_rsf.result[\"B\"] == 0].iloc[:, 5:].abs().sum())\n",
    "\n",
    "example_cph.result.iloc[:, 5:] = np.nan_to_num(\n",
    "            example_cph.result[example_cph.result[\"B\"] == 0].iloc[:, 5:]\n",
    "            / example_cph.result[example_cph.result[\"B\"] == 0].iloc[:, 5:].abs().sum())\n",
    "\n",
    "melted_example_norm_rsf = pd.melt(example_rsf.result, id_vars=\"variable_name\", value_vars=example_rsf.result.columns[6:])\n",
    "melted_example_norm_rsf[\"variable\"] = melted_example_norm_rsf[\"variable\"].str[4:].astype(float)\n",
    "melted_example_norm_rsf.to_csv(\"results/exp1_example_norm_rsf.csv\", index=False)\n",
    "\n",
    "melted_example_norm_cph = pd.melt(example_cph.result, id_vars=\"variable_name\", value_vars=example_cph.result.columns[6:])\n",
    "melted_example_norm_cph[\"variable\"] = melted_example_norm_cph[\"variable\"].str[4:].astype(float)\n",
    "melted_example_norm_cph.to_csv(\"results/exp1_example_norm_cph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing Signs Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_signs_rsf = np.sign(exp1_survshap_global_rsf.full_result.iloc[:, 6:].values)\n",
    "timestamps_rsf = exp1_survshap_global_rsf.timestamps\n",
    "\n",
    "shap_signs_cph = np.sign(exp1_survshap_global_cph.full_result.iloc[:, 6:].values)\n",
    "timestamps_cph = exp1_survshap_global_cph.timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, end_index = np.where((timestamps_rsf >= np.percentile(timestamps_rsf, 10)) & (timestamps_rsf <= np.percentile(timestamps_rsf, 90)))[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_ranges = []\n",
    "for row in shap_signs_rsf:\n",
    "    sign_ranges_row = []\n",
    "    last_sign = row[start_index]\n",
    "    start_time_sign_sequence = timestamps_rsf[start_index]\n",
    "    for i in range(start_index, end_index+1):\n",
    "        if row[i] != last_sign and row[i] != 0:\n",
    "            sign_ranges_row.append(last_sign*(timestamps_rsf[i-1] - start_time_sign_sequence))\n",
    "            start_time_sign_sequence = timestamps_rsf[i-1]\n",
    "        if row[i] != 0:\n",
    "            last_sign = row[i] \n",
    "    sign_ranges_row.append(last_sign*(timestamps_rsf[i] - start_time_sign_sequence))\n",
    "    sign_ranges.append(sign_ranges_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range < 0) for sign_ranges_row in sign_ranges]\n",
    "positive_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range > 0) for sign_ranges_row in sign_ranges]\n",
    "timestamps_range = timestamps_rsf[end_index] - timestamps_rsf[start_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_signs_005 = (np.abs(np.array(negative_range)) >= 0.05 * timestamps_range) & (np.array(positive_range) >= 0.05 * timestamps_range)\n",
    "changed_signs_01 = (np.abs(np.array(negative_range)) >= 0.1 * timestamps_range) & (np.array(positive_range) >= 0.1 * timestamps_range)\n",
    "changed_signs_02 = (np.abs(np.array(negative_range)) >= 0.2 * timestamps_range) & (np.array(positive_range) >= 0.2 * timestamps_range)\n",
    "csp_rsf = pd.DataFrame({\"variable_name\": exp1_survshap_global_rsf.full_result.variable_name, \n",
    "                                \"variable_value\": exp1_survshap_global_rsf.full_result.variable_value, \n",
    "                                \"index\": exp1_survshap_global_rsf.full_result.index, \n",
    "                                \"changed_signs_0.05\": changed_signs_005,\n",
    "                                \"changed_signs_0.1\": changed_signs_01,\n",
    "                                \"changed_signs_0.2\": changed_signs_02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, end_index = np.where((timestamps_cph >= np.percentile(timestamps_rsf, 10)) & (timestamps_cph <= np.percentile(timestamps_rsf, 90)))[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_ranges = []\n",
    "for row in shap_signs_cph:\n",
    "    sign_ranges_row = []\n",
    "    last_sign = row[start_index]\n",
    "    start_time_sign_sequence = timestamps_cph[start_index]\n",
    "    for i in range(start_index, end_index):\n",
    "        if row[i] != last_sign and row[i] != 0:\n",
    "            sign_ranges_row.append(last_sign*(timestamps_cph[i-1] - start_time_sign_sequence))\n",
    "            start_time_sign_sequence = timestamps_cph[i-1]\n",
    "        if row[i] != 0:\n",
    "            last_sign = row[i] \n",
    "    sign_ranges_row.append(last_sign*(timestamps_cph[i] - start_time_sign_sequence))\n",
    "    sign_ranges.append(sign_ranges_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range < 0) for sign_ranges_row in sign_ranges]\n",
    "positive_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range > 0) for sign_ranges_row in sign_ranges]\n",
    "timestamps_range = timestamps_cph[-1] - timestamps_cph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_signs_005 = (np.abs(np.array(negative_range)) >= 0.05 * timestamps_range) & (np.array(positive_range) >= 0.05 * timestamps_range)\n",
    "changed_signs_01 = (np.abs(np.array(negative_range)) >= 0.1 * timestamps_range) & (np.array(positive_range) >= 0.1 * timestamps_range)\n",
    "changed_signs_02 = (np.abs(np.array(negative_range)) >= 0.2 * timestamps_range) & (np.array(positive_range) >= 0.2 * timestamps_range)\n",
    "csp_cph = pd.DataFrame({\"variable_name\": exp1_survshap_global_cph.full_result.variable_name, \n",
    "                                \"variable_value\": exp1_survshap_global_cph.full_result.variable_value, \n",
    "                                \"index\": exp1_survshap_global_cph.full_result.index, \n",
    "                                \"changed_signs_0.05\": changed_signs_005,\n",
    "                                \"changed_signs_0.1\": changed_signs_01,\n",
    "                                \"changed_signs_0.2\": changed_signs_02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_rsf.groupby(\"variable_name\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_cph.groupby(\"variable_name\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Local accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_accuracy_from_shap_explanations(all_explanation, label, last_index=None):\n",
    "    if last_index is None:\n",
    "        last_index=len(all_explanation.timestamps)\n",
    "    diffs = []\n",
    "    preds = []\n",
    "    for explanation in all_explanation.individual_explanations:\n",
    "        preds.append(explanation.predicted_function[:last_index])\n",
    "        diffs.append(explanation.predicted_function[:last_index] - explanation.baseline_function[:last_index] - np.array(explanation.result.iloc[:, 6:].sum(axis=0))[:last_index])\n",
    "    diffs_squared = np.array(diffs)**2\n",
    "    E_diffs_sqared = np.mean(diffs_squared, axis=0)\n",
    "    preds_squared = np.array(preds)**2\n",
    "    E_preds_squared = np.mean(preds_squared, axis=0)\n",
    "    return  pd.DataFrame({\"time\": all_explanation.timestamps[:last_index], \"sigma\": np.sqrt(E_diffs_sqared) / np.sqrt(E_preds_squared), \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_rsf = get_local_accuracy_from_shap_explanations(exp1_survshap_global_rsf, \"RSF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_cph = get_local_accuracy_from_shap_explanations(exp1_survshap_global_cph, \"CPH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([local_accuracy_rsf, local_accuracy_cph]).to_csv(\"results/exp1_local_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GT-Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_grountruth_rsf = shap_grountruth_rsf.sort_values(by=[\"observation_index\", \"variable_index\"]) \n",
    "shap_grountruth_cph = shap_grountruth_cph.sort_values(by=[\"observation_index\", \"variable_index\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_rsf = shap_grountruth_rsf.values[:, 2:] - exp1_survshap_global_rsf.full_result[exp1_survshap_global_rsf.full_result[\"index\"].isin(shap_grountruth_rsf[\"observation_index\"])].values[:, 6:]\n",
    "diff_cph = shap_grountruth_cph.values[:, 2:] - exp1_survshap_global_cph.full_result[exp1_survshap_global_cph.full_result[\"index\"].isin(shap_grountruth_cph[\"observation_index\"])].values[:, 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_shap_profiles_rsf = shap_grountruth_rsf.values[:, 2:]\n",
    "gt_shap_profiles_cph = shap_grountruth_cph.values[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rsf = np.sqrt(np.array(np.mean(diff_rsf**2, axis=0), dtype=np.float64))\n",
    "rmse_gt_shap_profiles_rsf = np.sqrt(np.array(np.mean(gt_shap_profiles_rsf**2, axis=0), dtype=np.float64))\n",
    "rmse_cph = np.sqrt(np.array(np.mean(diff_cph**2, axis=0), dtype=np.float64))\n",
    "rmse_gt_shap_profiles_cph = np.sqrt(np.array(np.mean(gt_shap_profiles_cph**2, axis=0), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_comp_by_vars_rsf = np.zeros((5, 669))\n",
    "for i in range(5): \n",
    "    rmse = np.sqrt(np.array(np.mean(diff_rsf[i::5,] **2, axis=0), dtype=np.float64)) \n",
    "    normalization_factor = np.sqrt(np.array(np.mean(gt_shap_profiles_rsf[i::5,]**2, axis=0), dtype=np.float64))\n",
    "    gt_comp_by_vars_rsf[i,:] = rmse/normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_comp_by_vars_cph = np.zeros((5, 1000))\n",
    "for i in range(5): \n",
    "    rmse = np.sqrt(np.array(np.mean(diff_cph[i::5,] **2, axis=0), dtype=np.float64)) \n",
    "    normalization_factor = np.sqrt(np.array(np.mean(gt_shap_profiles_cph[i::5,]**2, axis=0), dtype=np.float64))\n",
    "    gt_comp_by_vars_cph[i,:] = rmse/normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(gt_comp_by_vars_rsf, index=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"], columns=timestamps_rsf).reset_index().rename(columns={\"index\": \"variable_name\"})\n",
    "pd.melt(tmp, id_vars=\"variable_name\", value_vars=tmp.columns).to_csv(\"results/exp1_gt_shap_rsf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(gt_comp_by_vars_cph, index=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"], columns=timestamps_cph).reset_index().rename(columns={\"index\": \"variable_name\"})\n",
    "pd.melt(tmp, id_vars=\"variable_name\", value_vars=tmp.columns).to_csv(\"results/exp1_gt_shap_cph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GT_Shapley(all_explanation, groundtruth, label):\n",
    "    corrs = []\n",
    "    for i in range(1, 100):\n",
    "        gt = (groundtruth.values[(i*5):(i*5+5), 2:])\n",
    "        obt = (np.array(all_explanation.full_result[all_explanation.full_result[\"index\"].isin(groundtruth[\"observation_index\"])].values[(i*5):(i*5+5), 6:], dtype=np.float64))\n",
    "        corrs.append(pd.DataFrame(gt).corrwith(pd.DataFrame(obt), axis=0))\n",
    "    return  pd.DataFrame({\"time\": all_explanation.timestamps, \"correlation\": np.array(corrs).mean(axis=0), \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([GT_Shapley(exp1_survshap_global_rsf, shap_grountruth_rsf, \"RSF\"), GT_Shapley(exp1_survshap_global_cph, shap_grountruth_cph, \"CPH\")]).to_csv(\"results/exp1_corr.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('survshap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e89d17bf3f53615b213f4c00662e1677a8885f31ece09e136535e9b43ddada0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
